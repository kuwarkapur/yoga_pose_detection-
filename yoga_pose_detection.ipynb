{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import array\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import posenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the posedetector function which helps us to detect pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BODY_PARTS = { \"Nose\": 0, \"Neck\": 1, \"RShoulder\": 2, \"RElbow\": 3, \"RWrist\": 4,\n",
    "               \"LShoulder\": 5, \"LElbow\": 6, \"LWrist\": 7, \"RHip\": 8, \"RKnee\": 9,\n",
    "               \"RAnkle\": 10, \"LHip\": 11, \"LKnee\": 12, \"LAnkle\": 13, \"REye\": 14,\n",
    "               \"LEye\": 15, \"REar\": 16, \"LEar\": 17, \"Background\": 18 }\n",
    "\n",
    "POSE_PAIRS = [ [\"Neck\", \"RShoulder\"], [\"Neck\", \"LShoulder\"], [\"RShoulder\", \"RElbow\"],\n",
    "               [\"RElbow\", \"RWrist\"], [\"LShoulder\", \"LElbow\"], [\"LElbow\", \"LWrist\"],\n",
    "               [\"Neck\", \"RHip\"], [\"RHip\", \"RKnee\"], [\"RKnee\", \"RAnkle\"], [\"Neck\", \"LHip\"],\n",
    "               [\"LHip\", \"LKnee\"], [\"LKnee\", \"LAnkle\"], [\"Neck\", \"Nose\"], [\"Nose\", \"REye\"],\n",
    "               [\"REye\", \"REar\"], [\"Nose\", \"LEye\"], [\"LEye\", \"LEar\"] ]\n",
    "\n",
    "width = 368\n",
    "height = 368                                            # setting up the\n",
    "                                                        # deafult values\n",
    "net = cv.dnn.readNetFromTensorflow(\"graph_opt.pb\")\n",
    "thr = 0.2\n",
    "\n",
    "def poseDetector(image):\n",
    "    imageWidth = image.shape[1]\n",
    "    imageHeight = image.shape[0]\n",
    "    \n",
    "    net.setInput(cv.dnn.blobFromImage(image, 1.0, (width, height), (127.5, 127.5, 127.5), swapRB=True, crop=False))\n",
    "    out = net.forward()\n",
    "    out = out[:, :19, :, :]  #basically its just here because we only need the first 19 elements\n",
    "\n",
    "    assert(len(BODY_PARTS) == out.shape[1])\n",
    "\n",
    "    points = []\n",
    "    for i in range(len(BODY_PARTS)):\n",
    "        # taking heatmap of respective body's part.\n",
    "        heatMap = out[0, i, :, :]\n",
    "\n",
    "        _, conf, _, point = cv.minMaxLoc(heatMap)\n",
    "        x = (imageWidth* point[0]) / out.shape[3]\n",
    "        y = (imageHeight * point[1]) / out.shape[2]\n",
    "        points.append((int(x), int(y)) if conf > thr else None)\n",
    "\n",
    "    for pair in POSE_PAIRS:\n",
    "        From = pair[0]\n",
    "        To = pair[1]\n",
    "        assert(From in BODY_PARTS)\n",
    "        assert(To in BODY_PARTS)\n",
    "\n",
    "        idFrom = BODY_PARTS[From]\n",
    "        idTo = BODY_PARTS[To]\n",
    "\n",
    "        if points[idFrom] and points[idTo]:\n",
    "            cv.line(image, points[idFrom], points[idTo], (0, 255, 0), 3)\n",
    "            cv.ellipse(image, points[idFrom], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)\n",
    "            cv.ellipse(image, points[idTo], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)\n",
    "\n",
    "    t, _ = net.getPerfProfile()\n",
    "\n",
    "    return image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is for accesing and preprocessing the training and testing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = ['downdog', 'goddess', 'plank', 'tree', 'warrior2']\n",
    "feature=[]\n",
    "feature_test=[]\n",
    "labels = []\n",
    "labels_test=[]\n",
    "def create_train(DIR,label,feat):\n",
    "    for person in poses:\n",
    "        path = os.path.join(DIR, person)\n",
    "        for img in os.listdir(path):\n",
    "            img_path = os.path.join(path,img)\n",
    "            img_array = cv.imread(img_path)\n",
    "            if img_array is None:\n",
    "                continue \n",
    "            else:\n",
    "                frame = poseDetector(img_array)\n",
    "                frame_new=cv.imread(img_path)\n",
    "                if(frame.shape[2]==frame_new.shape[2]):\n",
    "                    frame_diff=frame-frame_new\n",
    "                    feat.append(frame_diff)\n",
    "                    label.append(person)\n",
    "\n",
    "start=time.time()\n",
    "pose=create_train(r'C:\\Users\\Kuwar\\python projects\\yoga pose\\Train',labels,feature)\n",
    "features=np.array(feature)\n",
    "pose_t = create_train(r'C:\\Users\\Kuwar\\python projects\\yoga pose\\Test',labels_test,feature_test)\n",
    "features_test=np.array(feature_test)\n",
    "end=time.time()\n",
    "print('preprocessing done at:- ')\n",
    "print({end-start})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This part also mainly focuses on shaping up the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.reshape(len(labels),1)\n",
    "features_test.reshape(len(labels_test),1)\n",
    "print(features.shape)\n",
    "features_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test=pd.DataFrame(features_test ,columns=['feature_t'])\n",
    "data_test1=pd.DataFrame(labels_test ,columns=['label_t'])\n",
    "data=pd.DataFrame(features ,columns=['feature'])\n",
    "data1=pd.DataFrame(labels ,columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data['feature'])):\n",
    "    data['feature'][i]=data['feature'][i].flatten()\n",
    "for i in range(len(data_test['feature_t'])):\n",
    "    data_test['feature_t'][i]=data_test['feature_t'][i].flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LabelEncoder()\n",
    "labels=lr.fit_transform(data1['label'])\n",
    "labels_test=lr.fit_transform(data_test1['label_t'])\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing The Data for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3=[]\n",
    "test3=[]\n",
    "for i in range(len(data['feature'])):\n",
    "     train3.append(data['feature'][i].std())\n",
    "for i in range(len(data_test['feature_t'])):\n",
    "     test3.append(data_test['feature_t'][i].std())\n",
    "        \n",
    "train3=np.array(train3)\n",
    "train3=np.reshape(train3,(len(labels),1))\n",
    "test3=np.array(test3)\n",
    "test3=np.reshape(test3,(len(labels_test),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighbor Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(train3,labels)\n",
    "predict_knn=knn.predict(test3)\n",
    "print(classification_report(labels_test,predict_knn))\n",
    "print(confusion_matrix(labels_test,predict_knn))\n",
    "knn.fit(train3,labels)\n",
    "predict_knn1=knn.predict(train3)\n",
    "print(classification_report(labels,predict_knn1))\n",
    "print(confusion_matrix(labels,predict_knn1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
